{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTableQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/tapas-large-finetuned-wtq\", drop_rows_to_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTableQuestionAnswering.from_pretrained(\"google/tapas-large-finetuned-wtq\")\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "paths['train'] = \"../WikiTableQuestions/data/random-split-1-train.tsv\"\n",
    "#train_path = \"../WikiTableQuestions/data/training.tsv\"\n",
    "paths['dev'] = \"../WikiTableQuestions/data/random-split-1-dev.tsv\"\n",
    "paths['test'] = \"../WikiTableQuestions/data/pristine-unseen-tables.tsv\"\n",
    "table_csv_path = \"../WikiTableQuestions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_table(path):\n",
    "    with open(table_csv_path+path) as f:\n",
    "        reader = csv.reader(f, delimiter=',', quotechar='\"',quoting=csv.QUOTE_ALL,escapechar='\\\\')\n",
    "        headers = next(reader)\n",
    "        table = pd.DataFrame(list(reader),columns=headers).astype(str)\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        table = _load_table(os.path.join(table_csv_path,item.context))\n",
    "        encoding = self.tokenizer(table=table,\n",
    "                                  queries=item.utterance,\n",
    "                                  truncation=True,\n",
    "                                  padding=\"max_length\",\n",
    "                                  return_tensors=\"pt\"\n",
    "        )\n",
    "        # remove the batch dimension which the tokenizer adds by default\n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        encoding['id'] = idx\n",
    "        # add the float_answer which is also required (weak supervision for aggregation case)\n",
    "        return encoding\n",
    "    def __len__(self):\n",
    "       return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(path, batch_size = 4):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_NONE,escapechar='\\\\')\n",
    "        heads = next(reader)\n",
    "        data = pd.DataFrame(list(reader),columns=heads)\n",
    "    dataset = TableDataset(data, tokenizer)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2aggregation = {0: \"NONE\", 1: \"SUM\", 2: \"AVERAGE\", 3:\"COUNT\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.utils import text_utils\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect_cells_from_table(cell_coos, table):\n",
    "    cell_values = []\n",
    "    for cell in cell_coos:\n",
    "        value = str(table.iloc[cell[0],cell[1]])\n",
    "        cell_values.append(value)\n",
    "    return cell_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_convert_to_float(value):\n",
    "    float_value = text_utils.convert_to_float(value)\n",
    "    if math.isnan(float_value):\n",
    "        raise ValueError('Value is NaN %s' % value)\n",
    "    return float_value\n",
    "\n",
    "def _parse_value(value):\n",
    "  \"\"\"Parses a cell value to a number or lowercased string.\"\"\"\n",
    "  try:\n",
    "    return _safe_convert_to_float(value)\n",
    "  except ValueError:\n",
    "    try:\n",
    "      return value.lower()\n",
    "    except ValueError:\n",
    "      return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(aggregation_type, cell_coos,\n",
    "            table):\n",
    "  \"\"\"Executes predicted structure against a table to produce the denotation.\"\"\"\n",
    "  values = _collect_cells_from_table(cell_coos, table)\n",
    "  values_parsed = [_parse_value(value) for value in values]\n",
    "  values_parsed = tuple(values_parsed)\n",
    "  if aggregation_type == \"NONE\":\n",
    "    # In this case there is no aggregation\n",
    "    return values_parsed, values\n",
    "  else:  # Should perform aggregation.\n",
    "    if not values and (aggregation_type == \"AVERAGE\" or\n",
    "                       aggregation_type == \"SUM\"):\n",
    "      # Summing or averaging an empty set results in an empty set.\n",
    "      # NB: SQL returns null for sum over an empty set.\n",
    "      return tuple(), values\n",
    "    if aggregation_type == \"COUNT\":\n",
    "      denotation = len(values)\n",
    "    else:\n",
    "      # In this case all values must be numbers (to be summed or averaged).\n",
    "      try:\n",
    "        values_num = [text_utils.convert_to_float(value) for value in values]\n",
    "      except ValueError:\n",
    "        return values_parsed, values\n",
    "      if aggregation_type == \"SUM\":\n",
    "        denotation = sum(values_num)\n",
    "      elif aggregation_type == \"AVERAGE\":\n",
    "        denotation = sum(values_num) / len(values_num)\n",
    "      else:\n",
    "        raise ValueError('Unknwon aggregation type: %s' % aggregation_type)\n",
    "    return tuple([float(denotation)]), values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dataloader(paths['dev'])\n",
    "ds = dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = _load_table(os.path.join(table_csv_path,ds.data.iloc[0].context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idl = iter(dl)\n",
    "b = next(idl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(idl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = b.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "b = {k:v.to(device) for k,v in b.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1540/1540702108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_aggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    {k:v.to('cpu') for k,v in b.items()},\n",
    "    outputs.logits.cpu().detach(),\n",
    "    outputs.logits_aggregation.cpu().detach()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coors = predicted_answer_coordinates\n",
    "aggs = predicted_aggregation_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('tatiana volosozhar / maxim trankov',), ['Tatiana Volosozhar / Maxim Trankov'])\n",
      "(('new delhi, india',), ['New Delhi, India'])\n",
      "(('sweden',), ['Sweden'])\n",
      "((1694.0,), ['1694'])\n"
     ]
    }
   ],
   "source": [
    "for i,coor in enumerate(coors):\n",
    "    table = _load_table(os.path.join(table_csv_path, ds.data.iloc[int(ids[i])].context))\n",
    "    print(execute(id2aggregation[aggs[i]],coor,table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████▎                                       | 21/89 [02:11<07:05,  6.25s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3784/2479301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             coors, aggs = tokenizer.convert_logits_to_predictions(\n\u001b[1;32m     16\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, table_mask, labels, aggregation_labels, float_answer, numeric_values, numeric_values_scale, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         outputs = self.tapas(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "model.to(device)\n",
    "out = {}\n",
    "for split in ['dev','test']:\n",
    "    dl = get_dataloader(paths[split], batch_size=32)\n",
    "    ds = dl.dataset\n",
    "    out[split] = []\n",
    "    for b_num,batch in enumerate(tqdm(dl)):\n",
    "        ids = batch.pop('id')\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                outputs = model(**batch)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            coors, aggs = tokenizer.convert_logits_to_predictions(\n",
    "                {k:v.to('cpu') for k,v in batch.items()},\n",
    "                outputs.logits.cpu().detach(),\n",
    "                outputs.logits_aggregation.cpu().detach()\n",
    "            )\n",
    "        for i, coor in enumerate(coors):\n",
    "            table = _load_table(os.path.join(table_csv_path, ds.data.iloc[int(ids[i])].context))\n",
    "            denos,res = execute(id2aggregation[aggs[i]],coor,table)\n",
    "            out[split].append((denos,res))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m(1852)\u001b[0;36membedding\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1850 \u001b[0;31m        \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1851 \u001b[0;31m        \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1852 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1853 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1854 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(self.embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'self' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m(124)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    122 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 124 \u001b[0;31m        return F.embedding(\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    126 \u001b[0;31m            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(327)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    325 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    326 \u001b[0;31m            \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 327 \u001b[0;31m            \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    328 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    329 \u001b[0;31m        \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(906)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    904 \u001b[0;31m        \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    905 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 906 \u001b[0;31m        embedding_output = self.embeddings(\n",
      "\u001b[0m\u001b[0;32m    907 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    908 \u001b[0;31m        )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(self.embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.tapas.modeling_tapas.TapasEmbeddings'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.embeddings.num_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** torch.nn.modules.module.ModuleAttributeError: 'TapasEmbeddings' object has no attribute 'num_embeddings'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.embeddings.print_base()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** torch.nn.modules.module.ModuleAttributeError: 'TapasEmbeddings' object has no attribute 'print_base'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(self.embeddings.word_embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.sparse.Embedding'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.embeddings.word_embeddings.num_embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(1147)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1145 \u001b[0;31m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1146 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1147 \u001b[0;31m        outputs = self.tapas(\n",
      "\u001b[0m\u001b[0;32m   1148 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1149 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(input_ids)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30521)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.tapas.embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TapasEmbeddings(\n",
      "  (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "  (position_embeddings): Embedding(1024, 1024)\n",
      "  (token_type_embeddings_0): Embedding(3, 1024)\n",
      "  (token_type_embeddings_1): Embedding(256, 1024)\n",
      "  (token_type_embeddings_2): Embedding(256, 1024)\n",
      "  (token_type_embeddings_3): Embedding(2, 1024)\n",
      "  (token_type_embeddings_4): Embedding(256, 1024)\n",
      "  (token_type_embeddings_5): Embedding(256, 1024)\n",
      "  (token_type_embeddings_6): Embedding(10, 1024)\n",
      "  (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_3784/2165780.py\u001b[0m(15)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m            \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m            coors, aggs = tokenizer.convert_logits_to_predictions(\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m                \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ids\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
      "        686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699,\n",
      "        700, 701, 702, 703])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TableDataset object at 0x7f39bf1fb880>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  ds[672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([  101,  1996,  2060,  2308,  1005,  1055,  3453,  2007,  1996,  2168,\n",
      "         3926,  2051,  2004,  8183,  6643, 12417,  1999,  2262,   102,  3179,\n",
      "         2095,  2273,  1005,  1055,  3453,  2051,  1006,  1049,  1024,  1055,\n",
      "         2308,  1005,  1055,  3453,  2051,  1006,  1049,  1024,  1055,  3083,\n",
      "         2901, 20481,  2072,  2702,  5736,  1006,  4700,  1024,  4720, 12684,\n",
      "         2204,  2121,  3511,  1006,  5179,  1024,  5641,  3416,  2889,  2726,\n",
      "         6583, 11475,  1006,  9092,  4700,  1024,  2340, 15585,  5416, 12069,\n",
      "        16107,  1006,  5187,  1024,  2385,  3822,  2826,  8945,  4710, 17712,\n",
      "         7856,  2100,  4700,  1024,  5840,  1045, 20922, 11265, 27390,  2050,\n",
      "         5187,  1024,  2539,  4343,  2857,  5639, 21101,  2229,  1006, 16351,\n",
      "         2099,  4805,  1024,  2340,  1045, 20922, 11265, 27390,  2050,  5187,\n",
      "         1024,  5890,  4833,  2807,  5639, 21101,  2229,  1006, 16351,  2099,\n",
      "         4700,  1024,  4002, 21025,  4674,  6382,  4095, 16415,  3501,  5139,\n",
      "         1024,  4749,  5351,  2786, 11999, 16137,  3148,  1006,  6358,  3429,\n",
      "         1024,  5179,  9056, 23680,  4747,  5289,  1006,  5187,  1024,  2260,\n",
      "         5504,  2727,  5639, 21101,  2229,  1006, 16351,  2099,  4805,  1024,\n",
      "         5401,  4315,  8445,  2226, 10722,  7630,  4720,  1024,  4464,  5893,\n",
      "         2722,  5696, 17710, 10052,  1006,  6358,  4805,  1024,  5187,  9056,\n",
      "        23680,  4747,  5289,  1006,  4720,  1024,  4002,  6280,  2687, 26624,\n",
      "         3581,  2063,  1006, 16216,  2099,  4700,  1024,  2871, 14042, 11175,\n",
      "         1006, 16351,  2099,  5139,  1024,  2459,  6049,  2639,  4079, 10556,\n",
      "         5332,  4328,  3669,  4700,  1024,  4413, 14631, 11382, 24759, 16098,\n",
      "         2102,  5139,  1024,  4413,  6252,  2456, 16216,  5339, 15177,  2015,\n",
      "         1006,  4466,  1024,  2656,  2717,  4183, 13210,  3312,  1006,  4583,\n",
      "         1024,  2184,  5940,  2541, 21828, 24053,  2232,  1006,  9388,  4805,\n",
      "         1024,  2459,  2717,  4183, 13210,  3312,  1006,  4720,  1024,  4029,\n",
      "         6122,  2526,  4079, 10556,  5332,  4328,  3669,  4700,  1024,  2676,\n",
      "        16244,  1051,  1005,  7624,  1006,  4868,  1024,  4002,  6400,  2494,\n",
      "         2198,  9805,  2850,  1006,  9092,  4805,  1024,  3486, 16244,  1051,\n",
      "         1005,  7624,  1006,  5187,  1024,  2656,  6286,  2432, 21863, 24092,\n",
      "        14115,  7911,  1006,  4700,  1024,  2403,  3841,  6590,  3779,  1006,\n",
      "        17151,  4720,  1024,  3590,  5767,  2384,  2198,  9805,  2850,  1006,\n",
      "         9092,  4805,  1024,  3429,  4315,  8445,  2226, 10722,  7630,  4868,\n",
      "         1024,  2676,  5550,  2294,  4079, 12098,  8557,  2072,  1006,  4700,\n",
      "         1024,  2459,  8183,  6643, 12417,  1006, 16351,  2099,  4720,  1024,\n",
      "         4805,  4985,  2289,  5355, 11382, 20915,  1006,  6358,  4700,  1024,\n",
      "         2861,  3123, 24188, 10179,  7677,  2102,  5187,  1024,  4008,  3708,\n",
      "         2263,  6795, 11382,  7685, 20265,  1006,  4805,  1024,  4413, 13723,\n",
      "        22603,  1006, 16351,  2099,  4868,  1024,  2340,  3983,  2268,  9587,\n",
      "         2521,  4430,  1006, 16351,  2099,  4805,  1024,  2423,  1999,  2229,\n",
      "        10125,  9711,  1006,  4720,  1024,  3590,  7398,  2230,  3312,  1041,\n",
      "         8569,  3148,  1006,  3429,  1024,  2321,  4519,  3566, 19092,  2072,\n",
      "         1006,  4720,  1024,  6021, 13816,  2249,  7723, 12849,  8202,  1006,\n",
      "         6358,  4805,  1024,  2324,  2004, 12260,  7959,  2818, 21442, 10440,\n",
      "         4720,  1024,  4583, 13928,  2262,  4459,  9587,  3683,  2912,  1006,\n",
      "         4805,  1024,  2871,  8183,  6643, 12417,  1006, 24665,  2497,  5187,\n",
      "         1024,  5890, 13386,  2286, 14459,  6655,  2102,  1006,  6358,  4466,\n",
      "         1024,  6021,  7701, 11382, 24759, 16098,  2102,  5187,  1024,  5187,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'id': 672}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  model(**ds[672])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: forward() got an unexpected keyword argument 'id'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  e = ds[672]\n",
      "ipdb>  e.pop('id')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  model(**e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ValueError: Wrong shape for input_ids (shape torch.Size([512])) or attention_mask (shape torch.Size([512]))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'dict' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch['input_ids'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  e = {k:v.unsqueeze(0) for k,v in e.items()}\n",
      "ipdb>  e['input_ids'].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  model(**e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=None, logits=tensor([[-1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0031e+04,\n",
      "         -1.0032e+04, -1.0034e+04, -1.0034e+04, -1.0034e+04, -1.0034e+04,\n",
      "         -1.0033e+04, -1.0033e+04, -1.0033e+04, -1.0033e+04, -1.0033e+04,\n",
      "         -1.4503e+02, -1.4503e+02, -1.4503e+02, -1.4503e+02, -1.0030e+04,\n",
      "         -1.0030e+04, -1.0030e+04, -1.0030e+04, -1.0030e+04, -1.0024e+04,\n",
      "         -1.0025e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04,\n",
      "         -1.0025e+04, -1.0023e+04, -1.0023e+04, -1.0023e+04, -1.6582e+01,\n",
      "         -1.6582e+01, -1.6582e+01, -1.6582e+01, -1.6582e+01, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0022e+04, -1.0021e+04, -1.0023e+04,\n",
      "         -1.0023e+04, -1.0023e+04, -1.0023e+04, -1.0023e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.5782e+01, -1.5782e+01, -1.5782e+01,\n",
      "         -1.5782e+01, -1.5782e+01, -1.0020e+04, -1.0020e+04, -1.0020e+04,\n",
      "         -1.0024e+04, -1.0022e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0026e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04,\n",
      "         -1.8106e+01, -1.8106e+01, -1.8106e+01, -1.8106e+01, -1.8106e+01,\n",
      "         -1.0022e+04, -1.0022e+04, -1.0022e+04, -1.0021e+04, -1.0022e+04,\n",
      "         -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0023e+04, -1.0023e+04, -1.0023e+04, -2.6446e+01,\n",
      "         -2.6446e+01, -2.6446e+01, -2.6446e+01, -2.6446e+01, -1.0024e+04,\n",
      "         -1.0024e+04, -1.0024e+04, -1.0019e+04, -1.0021e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0021e+04, -2.1295e+01, -2.1295e+01,\n",
      "         -2.1295e+01, -2.1295e+01, -2.1295e+01, -2.1295e+01, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0024e+04, -1.0025e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0028e+04,\n",
      "         -1.0028e+04, -1.0028e+04, -1.7607e+01, -1.7607e+01, -1.7607e+01,\n",
      "         -1.7607e+01, -1.7607e+01, -1.0027e+04, -1.0027e+04, -1.0027e+04,\n",
      "         -1.0019e+04, -1.0020e+04, -1.0023e+04, -1.0023e+04, -1.0023e+04,\n",
      "         -1.0023e+04, -1.0023e+04, -1.0023e+04, -1.0021e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.8015e+01, -1.8015e+01, -1.8015e+01, -1.8015e+01,\n",
      "         -1.8015e+01, -1.0023e+04, -1.0023e+04, -1.0023e+04, -1.0022e+04,\n",
      "         -1.0023e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04, -2.6921e+01,\n",
      "         -2.6921e+01, -2.6921e+01, -2.6921e+01, -2.6921e+01, -1.0025e+04,\n",
      "         -1.0025e+04, -1.0025e+04, -1.0017e+04, -1.0019e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0021e+04,\n",
      "         -1.0018e+04, -1.0018e+04, -1.0018e+04, -1.8833e+01, -1.8833e+01,\n",
      "         -1.8833e+01, -1.8833e+01, -1.8833e+01, -1.0019e+04, -1.0019e+04,\n",
      "         -1.0019e+04, -1.0018e+04, -1.0020e+04, -1.0024e+04, -1.0024e+04,\n",
      "         -1.0024e+04, -1.0024e+04, -1.0024e+04, -1.0022e+04, -1.0022e+04,\n",
      "         -1.0022e+04, -1.9883e+01, -1.9883e+01, -1.9883e+01, -1.9883e+01,\n",
      "         -1.9883e+01, -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0013e+04,\n",
      "         -1.0013e+04, -1.0014e+04, -1.0014e+04, -1.0014e+04, -1.0014e+04,\n",
      "         -1.0014e+04, -1.0014e+04, -1.0014e+04, -1.0014e+04, -1.1270e+01,\n",
      "         -1.1270e+01, -1.1270e+01, -1.1270e+01, -1.1270e+01, -1.0015e+04,\n",
      "         -1.0015e+04, -1.0015e+04, -1.0024e+04, -1.0026e+04, -1.0029e+04,\n",
      "         -1.0029e+04, -1.0029e+04, -1.0029e+04, -1.0029e+04, -1.0029e+04,\n",
      "         -1.0029e+04, -1.0029e+04, -3.1396e+01, -3.1396e+01, -3.1396e+01,\n",
      "         -3.1396e+01, -3.1396e+01, -1.0030e+04, -1.0030e+04, -1.0030e+04,\n",
      "         -1.0021e+04, -1.0024e+04, -1.0024e+04, -1.0024e+04, -1.0024e+04,\n",
      "         -1.0024e+04, -1.0024e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04,\n",
      "         -1.4377e+01, -1.4377e+01, -1.4377e+01, -1.4377e+01, -1.4377e+01,\n",
      "         -1.0027e+04, -1.0027e+04, -1.0027e+04, -1.0017e+04, -1.0019e+04,\n",
      "         -1.0018e+04, -1.0018e+04, -1.0018e+04, -1.0018e+04, -1.0018e+04,\n",
      "         -1.0018e+04, -1.0018e+04, -1.0018e+04, -2.5229e+00, -2.5229e+00,\n",
      "         -2.5229e+00, -2.5229e+00, -2.5229e+00, -1.0015e+04, -1.0015e+04,\n",
      "         -1.0015e+04, -1.0023e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0027e+04, -1.0027e+04,\n",
      "         -1.0027e+04, -2.5103e+01, -2.5103e+01, -2.5103e+01, -2.5103e+01,\n",
      "         -2.5103e+01, -1.0025e+04, -1.0025e+04, -1.0025e+04, -1.0024e+04,\n",
      "         -1.0028e+04, -1.0028e+04, -1.0028e+04, -1.0028e+04, -1.0028e+04,\n",
      "         -1.0028e+04, -1.0029e+04, -1.0029e+04, -1.0029e+04, -2.6930e+01,\n",
      "         -2.6930e+01, -2.6930e+01, -2.6930e+01, -2.6930e+01, -1.0027e+04,\n",
      "         -1.0027e+04, -1.0027e+04, -1.0017e+04, -1.0020e+04, -1.0014e+04,\n",
      "         -1.0014e+04, -1.0014e+04, -1.0014e+04, -1.0014e+04, -1.0017e+04,\n",
      "         -1.0017e+04, -1.0017e+04, -1.6456e+01, -1.6456e+01, -1.6456e+01,\n",
      "         -1.6456e+01, -1.6456e+01, -1.6456e+01, -1.0016e+04, -1.0016e+04,\n",
      "         -1.0016e+04, -1.0025e+04, -1.0026e+04, -1.0027e+04, -1.0027e+04,\n",
      "         -1.0027e+04, -1.0027e+04, -1.0027e+04, -1.0028e+04, -1.0028e+04,\n",
      "         -1.0028e+04, -1.9121e+01, -1.9121e+01, -1.9121e+01, -1.9121e+01,\n",
      "         -1.9121e+01, -1.0027e+04, -1.0027e+04, -1.0027e+04, -1.0027e+04,\n",
      "         -1.0025e+04, -1.0031e+04, -1.0031e+04, -1.0031e+04, -1.0031e+04,\n",
      "         -1.0031e+04, -1.0029e+04, -1.0029e+04, -1.0029e+04, -2.0754e+01,\n",
      "         -2.0754e+01, -2.0754e+01, -2.0754e+01, -2.0754e+01, -1.0027e+04,\n",
      "         -1.0027e+04, -1.0027e+04, -1.0018e+04, -1.0020e+04, -1.0018e+04,\n",
      "         -1.0018e+04, -1.0018e+04, -1.0018e+04, -1.0018e+04, -1.0018e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0021e+04,  4.5191e+00,  4.5191e+00,\n",
      "          4.5191e+00,  4.5191e+00,  4.5191e+00, -1.0021e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0028e+04, -1.0031e+04, -1.0034e+04, -1.0034e+04,\n",
      "         -1.0034e+04, -1.0034e+04, -1.0034e+04, -1.0032e+04, -1.0032e+04,\n",
      "         -1.0032e+04, -3.1098e+01, -3.1098e+01, -3.1098e+01, -3.1098e+01,\n",
      "         -3.1098e+01, -1.0033e+04, -1.0033e+04, -1.0033e+04, -1.0022e+04,\n",
      "         -1.0023e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04, -1.0026e+04,\n",
      "         -1.0026e+04, -1.0025e+04, -1.0025e+04, -1.0025e+04, -1.1923e+01,\n",
      "         -1.1923e+01, -1.1923e+01, -1.1923e+01, -1.1923e+01, -1.1923e+01,\n",
      "         -1.0024e+04, -1.0024e+04, -1.0024e+04, -1.0016e+04, -1.0028e+04,\n",
      "         -1.0013e+04, -1.0013e+04, -1.0013e+04, -1.0013e+04, -1.0013e+04,\n",
      "         -1.0022e+04, -1.0022e+04, -1.0022e+04, -1.7836e+01, -1.7836e+01,\n",
      "         -1.7836e+01, -1.7836e+01, -1.7836e+01, -1.7836e+01, -1.0019e+04,\n",
      "         -1.0019e+04, -1.0019e+04, -1.0020e+04, -1.0020e+04, -1.0021e+04,\n",
      "         -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0021e+04, -1.0022e+04,\n",
      "         -1.0022e+04, -1.0022e+04, -1.1544e+01, -1.1544e+01, -1.1544e+01,\n",
      "         -1.1544e+01, -1.1544e+01, -1.0019e+04, -1.0019e+04, -1.0019e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04, -1.0012e+04,\n",
      "         -1.0012e+04, -1.0012e+04]], grad_fn=<ViewBackward>), logits_aggregation=tensor([[19.1263, -3.2023,  0.7264,  0.4789]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  e = {k:v.unsqueeze(0) for k,v in ds[673].items() if k!='id'}\n",
      "ipdb>  model(**e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=None, logits=tensor([[-10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10024.9902,   -120.1096, -10028.1289, -10028.4385,\n",
      "         -10032.3018, -10029.1934, -10001.0068,     40.5817, -10005.4443,\n",
      "          -9999.3262,  -9999.6553, -10004.0439, -10026.6182,    -65.3360,\n",
      "         -10027.0996, -10026.2617, -10026.5078, -10022.0879, -10020.7344,\n",
      "            -63.4198, -10019.3984, -10021.7285, -10026.9883, -10020.3584,\n",
      "         -10023.4551,    -25.8319, -10020.5820, -10021.1797, -10023.9072,\n",
      "         -10020.4678, -10030.7500,    -53.3926, -10028.3330, -10026.6260,\n",
      "         -10029.3369, -10026.8203, -10033.2549,    -95.9602,    -95.9602,\n",
      "         -10031.9531, -10031.6836, -10034.7754, -10031.3086, -10032.2021,\n",
      "            -62.5598, -10030.8506, -10030.9717, -10035.0566, -10029.4746,\n",
      "         -10032.9395,   -112.8097, -10033.3906, -10031.9111, -10037.2568,\n",
      "         -10031.5771, -10034.3984,    -95.6047, -10033.2139, -10031.6377,\n",
      "         -10035.9590, -10030.0791, -10031.1260,    -78.2333, -10031.0312,\n",
      "         -10029.2900, -10030.6797, -10028.5361, -10032.2051,    -91.5804,\n",
      "         -10032.0244, -10031.0352, -10031.5811, -10028.8428, -10032.8330,\n",
      "            -62.9460, -10036.1719, -10034.4492, -10033.5508, -10031.2959,\n",
      "         -10033.1670,    -64.0914, -10034.6104, -10033.5996, -10033.3604,\n",
      "         -10031.2637, -10033.2969,   -102.1850, -10034.6367, -10032.9375,\n",
      "         -10032.9688, -10031.4482, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682, -10025.8682, -10025.8682, -10025.8682,\n",
      "         -10025.8682, -10025.8682]], grad_fn=<ViewBackward>), logits_aggregation=tensor([[20.7523, -3.1015, -0.4115,  0.6315]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  e = {k:v.unsqueeze(0) for k,v in ds[674].items() if k!='id'}\n",
      "ipdb>  model(**e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=None, logits=tensor([[-10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10107.3887, -10107.4600, -10097.0869,\n",
      "         -10169.3242,   -331.1098, -10062.0576, -10080.1152, -10073.7158,\n",
      "         -10118.5996, -10080.6934, -10118.9717, -10076.7773,   -189.2221,\n",
      "         -10061.2461, -10047.4688, -10037.3457, -10037.3457, -10037.3457,\n",
      "         -10021.3682, -10006.5547, -10023.1514, -10019.2578,    280.4255,\n",
      "         -10011.6885, -10011.6885, -10011.6885, -10007.5850, -10006.8662,\n",
      "         -10070.0059, -10057.6396, -10075.5498, -10082.1406,   -162.9949,\n",
      "         -10049.6045, -10048.4355, -10042.9238, -10073.2051, -10058.1211,\n",
      "         -10069.7002, -10066.2783,   -134.9747, -10044.8047, -10056.9482,\n",
      "         -10043.9834, -10088.7051, -10086.7275, -10095.8252, -10092.2129,\n",
      "           -200.9371, -10070.9414, -10093.8027, -10050.2051, -10116.6377,\n",
      "         -10088.2002, -10090.5723, -10115.7090,   -289.1569, -10101.1943,\n",
      "         -10100.8379, -10066.0439, -10066.0439, -10102.1562, -10076.6182,\n",
      "         -10073.7471, -10091.4023,   -162.5320, -10071.3320, -10076.3174,\n",
      "         -10045.1152, -10136.5361, -10101.4668, -10117.7959, -10134.1357,\n",
      "           -206.2843, -10094.0605, -10090.4990, -10090.4990, -10068.5742,\n",
      "         -10068.5742, -10141.6562, -10083.5781, -10111.4912, -10122.9863,\n",
      "           -278.9883, -10086.1680, -10098.7725, -10098.7725, -10066.9355,\n",
      "         -10066.9355, -10174.4072, -10102.6816, -10147.7744, -10180.9170,\n",
      "           -307.4875, -10111.2686, -10142.3633, -10163.6836, -10093.4434,\n",
      "         -10141.7939, -10156.8174,   -207.4597, -10094.6816, -10101.6133,\n",
      "         -10071.3584, -10171.4600, -10126.7158, -10141.3906, -10156.3467,\n",
      "           -289.3201, -10110.3350, -10149.0059, -10082.2432, -10164.4492,\n",
      "         -10101.3877, -10145.0762, -10174.5254,   -257.7038, -10103.3633,\n",
      "         -10138.0615, -10085.0166, -10085.0166, -10085.0166, -10162.4883,\n",
      "         -10122.2842, -10148.9062, -10177.9287,   -275.8391, -10106.4268,\n",
      "         -10149.6055, -10163.7656, -10100.3604, -10100.3604, -10151.2295,\n",
      "         -10164.1133,   -283.3170, -10106.6523, -10096.4775, -10184.9609,\n",
      "         -10107.6436, -10156.9961, -10193.3057,   -324.1036, -10130.9287,\n",
      "         -10116.3350, -10161.9170, -10121.2539, -10148.4502, -10156.4297,\n",
      "           -222.5648, -10108.9922, -10126.6406, -10085.1543, -10173.6279,\n",
      "         -10135.7178, -10157.8877, -10144.8867,   -253.6685, -10112.7568,\n",
      "         -10162.7734, -10097.3926, -10134.4873, -10096.0186, -10117.1943,\n",
      "         -10104.1699,   -206.8269, -10093.8203, -10089.1543, -10089.1543,\n",
      "         -10162.8672, -10138.5439, -10142.3477, -10148.8750,   -185.0596,\n",
      "         -10123.3613, -10137.7549, -10076.1592, -10161.5146, -10137.3574,\n",
      "         -10134.3691, -10148.2188,   -270.7305, -10128.2627, -10161.6016,\n",
      "         -10097.5410, -10129.9736, -10096.8105, -10116.8174, -10125.4531,\n",
      "           -210.1941, -10097.1289, -10133.6357, -10078.5547, -10078.5547,\n",
      "         -10078.5547, -10159.0625, -10109.0830, -10115.3818, -10157.0693,\n",
      "           -294.0261, -10126.0166, -10173.9053, -10101.5908, -10101.5908,\n",
      "         -10101.5908, -10129.6191, -10105.8662, -10107.9365, -10127.3262,\n",
      "           -258.3207, -10094.5820, -10104.5957, -10173.9424, -10143.9043,\n",
      "         -10137.6797, -10182.3828,   -315.7520, -10149.2344, -10158.1328,\n",
      "         -10179.1357, -10153.9570, -10152.8057, -10168.4863,   -259.2029,\n",
      "         -10131.7363, -10180.9600, -10099.1650, -10174.1279, -10122.6631,\n",
      "         -10135.5439, -10148.4990,   -299.6736, -10121.2412, -10135.2246,\n",
      "         -10091.0098, -10140.2529, -10107.4160, -10115.4404, -10137.8428,\n",
      "           -292.6372, -10110.2354, -10114.8135, -10159.3311, -10116.0908,\n",
      "         -10122.1748, -10130.5586,   -200.5952, -10082.4990, -10082.4990,\n",
      "         -10145.4785, -10078.2080, -10159.2793, -10107.3564, -10139.8906,\n",
      "         -10160.5625,   -260.2630, -10104.5479, -10197.6797, -10083.7891,\n",
      "         -10150.5283, -10111.1426, -10121.1943, -10153.9023,   -294.9642,\n",
      "         -10107.3848, -10156.9854, -10087.2676, -10162.6025, -10130.5967,\n",
      "         -10142.6025, -10150.4912,   -299.6013, -10117.5498, -10153.9844,\n",
      "         -10091.1816, -10139.9736, -10107.7725, -10110.2627, -10146.8398,\n",
      "           -268.9540, -10098.4141, -10150.5186, -10085.6426, -10190.6152,\n",
      "         -10123.9404, -10148.6377, -10186.2686,   -306.5601, -10102.0957,\n",
      "         -10102.0957, -10149.5830, -10153.9971, -10086.5605, -10115.7842,\n",
      "         -10148.8965,   -277.2242, -10096.8047, -10104.8877, -10168.6133,\n",
      "         -10098.2168, -10098.2168, -10126.3975, -10140.0693,   -310.4711,\n",
      "         -10120.3467, -10199.1006, -10090.5928, -10186.1328, -10143.1865,\n",
      "         -10130.3086, -10178.1260,   -306.2369, -10144.3730, -10222.1709,\n",
      "         -10098.7744, -10177.6924, -10108.2812, -10113.8047, -10161.9834,\n",
      "           -245.3531, -10113.8994, -10155.3750, -10120.5977, -10105.2949,\n",
      "         -10093.7031, -10140.4795,   -263.7290, -10089.1182, -10118.0127,\n",
      "         -10077.1094, -10184.5840, -10081.1553, -10081.1553, -10100.2002,\n",
      "         -10130.1279,   -282.3244, -10100.6914, -10099.8594, -10099.8594,\n",
      "         -10077.7080, -10190.1963, -10117.9141, -10129.6768, -10142.7988,\n",
      "           -183.8103, -10099.4248, -10157.5508, -10068.6768, -10244.4678,\n",
      "         -10116.1387, -10107.6602, -10119.3848,   -205.6714, -10120.8281,\n",
      "         -10155.3545, -10228.6445, -10120.4170, -10182.8359, -10177.1484,\n",
      "           -297.8183, -10114.4883, -10172.5127, -10079.1963, -10224.8174,\n",
      "         -10136.2773, -10127.3467, -10172.9268,   -316.2171, -10140.4043,\n",
      "         -10237.4102, -10093.4082, -10215.6924, -10200.4971, -10154.7617,\n",
      "         -10182.4473,   -291.5783, -10165.6865, -10153.5938, -10153.5938,\n",
      "         -10108.7646, -10238.3408, -10112.1348, -10142.9805, -10174.1641,\n",
      "           -322.9674, -10137.7520, -10130.1709, -10130.1709, -10082.6660,\n",
      "         -10181.7002, -10080.6279, -10083.8096, -10087.1328,   -280.0110,\n",
      "         -10059.6865, -10205.2666, -10130.3389, -10086.0811, -10094.0400,\n",
      "         -10094.8809,   -218.8640, -10094.5420, -10137.9014, -10062.0195,\n",
      "         -10141.8867, -10082.6914, -10095.9834, -10113.9854,   -257.9964,\n",
      "         -10087.8340, -10092.9766, -10092.9766, -10058.7441, -10180.3887,\n",
      "         -10088.9863, -10097.8145, -10124.6201,   -313.3481, -10069.8809,\n",
      "         -10069.8809, -10109.4834, -10072.2402, -10055.7686, -10052.5703,\n",
      "         -10080.0596,   -204.7448, -10047.1699, -10046.5518, -10043.5547,\n",
      "         -10171.5869, -10080.0273, -10080.0273, -10080.0273, -10101.4678,\n",
      "         -10136.5615,   -289.3716, -10087.8242, -10110.3076, -10110.3076,\n",
      "         -10067.5293, -10167.5713, -10093.7891, -10098.9648, -10130.0908,\n",
      "           -323.1311, -10080.8555, -10092.7891, -10092.7891, -10067.2910,\n",
      "         -10153.5498, -10071.3965, -10120.1592, -10140.5322,   -301.4225,\n",
      "         -10079.4023, -10093.8086, -10061.9268, -10061.9268, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928, -10049.5928, -10049.5928, -10049.5928,\n",
      "         -10049.5928, -10049.5928]], grad_fn=<ViewBackward>), logits_aggregation=tensor([[ 0.1263, 23.5788, -2.7948,  4.8388]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  e = {k:v.unsqueeze(0) for k,v in ds[675].items() if k!='id'}\n",
      "ipdb>  model(**e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TableQuestionAnsweringOutput(loss=None, logits=tensor([[-10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520,   -115.3408, -10116.3398, -10106.7861, -10071.4707,\n",
      "         -10080.2998, -10080.2998,   -148.1307,   -148.1307,   -148.1307,\n",
      "         -10139.2559, -10139.2559, -10071.0430, -10071.0430, -10094.5801,\n",
      "         -10094.5801, -10136.7051, -10136.7051, -10136.7051,    -35.1360,\n",
      "            -35.1360, -10039.7480, -10057.6074, -10057.6074, -10042.0381,\n",
      "         -10042.0381, -10044.1768, -10044.1768, -10044.1768,    -46.4297,\n",
      "            -46.4297,    -46.4297, -10087.3633, -10087.3633, -10087.3633,\n",
      "         -10075.0518, -10075.0518, -10049.7012, -10049.7012, -10055.7383,\n",
      "         -10055.7383, -10055.7383,    -38.0143,    -38.0143, -10055.0879,\n",
      "         -10055.0879, -10055.0879, -10055.4980, -10055.4980, -10043.7480,\n",
      "         -10043.7480, -10043.9111, -10043.9111,    153.1454,    153.1454,\n",
      "          -9901.1260,  -9901.1260,  -9912.2852,  -9912.2852,  -9856.4043,\n",
      "          -9856.4043,  -9862.1357,  -9862.1357,  -9862.1357,     14.6038,\n",
      "             14.6038,     14.6038,  -9986.1592, -10024.9424, -10024.9424,\n",
      "         -10004.7842, -10004.7842, -10006.8428, -10006.8428, -10006.8428,\n",
      "           -161.8904,   -161.8904,   -161.8904, -10149.4219, -10149.4219,\n",
      "         -10042.7549, -10042.7549, -10097.7041, -10097.7041, -10128.7393,\n",
      "         -10128.7393, -10128.7393,    -36.7417,    -36.7417,    -36.7417,\n",
      "         -10043.2354, -10046.7197, -10046.7197, -10038.8057, -10038.8057,\n",
      "         -10040.4805, -10040.4805, -10040.4805,    -43.3708, -10068.4297,\n",
      "         -10068.4297, -10068.4297, -10066.4619, -10066.4619, -10045.1650,\n",
      "         -10050.2109, -10050.2109,   -212.5753,   -212.5753, -10153.0664,\n",
      "         -10153.0664, -10077.8135, -10077.8135, -10131.4619, -10131.4619,\n",
      "         -10131.4619, -10143.0439, -10143.0439,    -44.6478,    -44.6478,\n",
      "         -10068.1855, -10068.1855, -10068.1855, -10079.3838, -10079.3838,\n",
      "         -10052.5293, -10052.5293, -10052.5293, -10052.4102, -10052.4102,\n",
      "            -34.8148, -10046.2451, -10046.2451, -10046.2451, -10054.9072,\n",
      "         -10054.9072, -10042.5977, -10042.5977, -10042.5977, -10041.4824,\n",
      "         -10041.4824,     39.3043,     39.3043,  -9969.6484,  -9969.6484,\n",
      "          -9981.4990,  -9981.4990,  -9982.2129,  -9982.2129,  -9982.2129,\n",
      "          -9978.4473,  -9978.4473,   -148.4239,   -148.4239, -10103.2881,\n",
      "         -10103.2881, -10061.3203, -10061.3203, -10112.9219, -10112.9219,\n",
      "         -10112.9219, -10095.1230, -10095.1230,   -205.8369,   -205.8369,\n",
      "         -10170.9277, -10170.9277, -10091.6084, -10091.6084, -10133.2559,\n",
      "         -10133.2559, -10133.2559, -10134.9746, -10134.9746,    -81.0801,\n",
      "            -81.0801,    -81.0801, -10153.4824, -10153.4824, -10153.4824,\n",
      "         -10103.6582, -10103.6582, -10125.8809, -10125.8809, -10125.8809,\n",
      "         -10116.0947, -10116.0947, -10116.0947,   -162.5611,   -162.5611,\n",
      "           -162.5611, -10154.0127, -10154.0127, -10069.8643, -10069.8643,\n",
      "         -10138.0986, -10138.0986, -10138.0986, -10126.3262, -10126.3262,\n",
      "           -223.6469,   -223.6469, -10215.7188, -10215.7188, -10124.9775,\n",
      "         -10124.9775, -10197.1084, -10197.1084, -10197.1084, -10183.1348,\n",
      "         -10183.1348,    -46.7744,    -46.7744,    -46.7744, -10061.9473,\n",
      "         -10080.8828, -10080.8828, -10074.0068, -10074.0068, -10074.0068,\n",
      "         -10060.1094, -10060.1094,   -205.7017,   -205.7017, -10173.2275,\n",
      "         -10173.2275, -10088.0625, -10088.0625, -10161.5518, -10161.5518,\n",
      "         -10161.5518, -10120.4580, -10120.4580,   -226.4149,   -226.4149,\n",
      "           -226.4149, -10198.8701, -10198.8701, -10104.9336, -10104.9336,\n",
      "         -10196.5322, -10196.5322, -10196.5322, -10144.1621, -10144.1621,\n",
      "            -55.8739, -10068.9990, -10068.9990, -10068.9990, -10084.9111,\n",
      "         -10084.9111, -10075.7109, -10075.7109, -10075.7109, -10056.5371,\n",
      "         -10056.5371,   -234.0748, -10209.9648, -10209.9648, -10125.9004,\n",
      "         -10125.9004, -10190.8262, -10190.8262, -10190.8262, -10164.3125,\n",
      "         -10164.3125,   -249.1505,   -249.1505, -10206.2031, -10206.2031,\n",
      "         -10112.0645, -10112.0645, -10206.7822, -10206.7822, -10182.2598,\n",
      "         -10182.2598,   -265.3170, -10232.5537, -10232.5537, -10141.4609,\n",
      "         -10141.4609, -10208.3174, -10208.3174, -10141.9033, -10141.9033,\n",
      "         -10141.9033,    151.3881,    151.3881,    151.3881,  -9896.2090,\n",
      "          -9896.2090,  -9912.3389,  -9912.3389,  -9862.4355,  -9862.4355,\n",
      "          -9891.7471,  -9891.7471,  -9891.7471,    -32.3899,    -32.3899,\n",
      "         -10042.2002, -10042.2002, -10042.2002, -10050.9922, -10050.9922,\n",
      "         -10037.6387, -10037.6387, -10037.8477, -10037.8477,    -39.4430,\n",
      "            -39.4430, -10052.9355, -10052.9355, -10052.9355, -10057.1475,\n",
      "         -10057.1475, -10045.1494, -10045.1494, -10045.8281, -10045.8281,\n",
      "           -231.7171,   -231.7171, -10167.2695, -10167.2695, -10094.0498,\n",
      "         -10094.0498, -10192.8672, -10192.8672, -10145.2031, -10145.2031,\n",
      "             85.8896,     85.8896,  -9941.7871,  -9941.7871,  -9962.8877,\n",
      "          -9962.8877,  -9910.4492,  -9910.4492,  -9922.5996,  -9922.5996,\n",
      "          -9922.5996,   -183.1230,   -183.1230, -10164.3418, -10164.3418,\n",
      "         -10066.6992, -10066.6992, -10160.6650, -10160.6650, -10131.7764,\n",
      "         -10131.7764,    -30.7659,    -30.7659, -10038.7236, -10038.7236,\n",
      "         -10038.7236, -10042.3848, -10042.3848, -10034.7471, -10034.7471,\n",
      "         -10034.7773, -10034.7773,   -131.5608,   -131.5608, -10072.9551,\n",
      "         -10072.9551, -10051.4082, -10051.4082, -10092.1758, -10092.1758,\n",
      "         -10087.5273, -10087.5273, -10087.5273,    -36.6372,    -36.6372,\n",
      "            -36.6372, -10046.8789, -10046.8789, -10046.8789, -10048.7461,\n",
      "         -10048.7461, -10038.6260, -10038.6260, -10041.7373, -10041.7373,\n",
      "         -10041.7373,    -36.6154,    -36.6154,    -36.6154,    -36.6154,\n",
      "         -10045.4092, -10045.4092, -10045.4092, -10046.6211, -10046.6211,\n",
      "         -10039.0410, -10039.0410, -10039.3438, -10039.3438, -10039.3438,\n",
      "         -10039.3438,    -39.6915,    -39.6915,    -39.6915, -10049.5732,\n",
      "         -10049.5732, -10049.5732, -10053.3457, -10053.3457, -10039.2510,\n",
      "         -10039.2510, -10039.9316, -10039.9316,    -31.5459,    -31.5459,\n",
      "            -31.5459, -10039.8428, -10039.8428, -10039.8428, -10045.7969,\n",
      "         -10045.7969, -10035.5410, -10035.5410, -10036.4160, -10036.4160,\n",
      "         -10036.4160,    -26.6664,    -26.6664,    -26.6664, -10038.6641,\n",
      "         -10038.6641, -10038.6641, -10045.7812, -10045.7812, -10033.2412,\n",
      "         -10033.2412, -10033.9160, -10033.9160, -10033.9160, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520, -10010.7520, -10010.7520, -10010.7520,\n",
      "         -10010.7520, -10010.7520]], grad_fn=<ViewBackward>), logits_aggregation=tensor([[ -2.3557, -10.5770,  -8.3837,  16.6012]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
    "        686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699,\n",
    "        700, 701, 702, 703]\n",
    "error_idxs = []\n",
    "outs = []\n",
    "dl = get_dataloader(paths['dev'], batch_size=32)\n",
    "ds = dl.dataset\n",
    "for idx in range(len(ds)):\n",
    "    e = {k:v.unsqueeze(0) for k,v in ds[idx].items() if k!='id'}\n",
    "    try:\n",
    "        o = model(**e)\n",
    "        outs.append(o)\n",
    "    except IndexError:\n",
    "        print(idx)\n",
    "        error_idxs.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = {k:v.unsqueeze(0) for k,v in ds[683].items() if k!='id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds.data.iloc[683]\n",
    "table = _load_table(table_csv_path+item.context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'City', 'State, province, dept., etc.', 'Country', 'Notes'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>City</th>\n",
       "      <th>State, province, dept., etc.</th>\n",
       "      <th>Country</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000 BC</td>\n",
       "      <td>Puerto Hormiga Culture</td>\n",
       "      <td>Cartagena</td>\n",
       "      <td>Colombia</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3710 BC</td>\n",
       "      <td>Aspero</td>\n",
       "      <td>Norte Chico</td>\n",
       "      <td>Peru</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2627 BC</td>\n",
       "      <td>Caral</td>\n",
       "      <td>Norte Chico</td>\n",
       "      <td>Peru</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700 BC</td>\n",
       "      <td>Ticul</td>\n",
       "      <td>Yucatán</td>\n",
       "      <td>Mexico</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500 BC</td>\n",
       "      <td>Cholula</td>\n",
       "      <td>Puebla</td>\n",
       "      <td>Mexico</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1960</td>\n",
       "      <td>Brasília</td>\n",
       "      <td>Distrito Federal</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Created in 1960 as the national capital.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>1970</td>\n",
       "      <td>Belmopan</td>\n",
       "      <td>Cayo</td>\n",
       "      <td>Belize</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1970</td>\n",
       "      <td>Linden</td>\n",
       "      <td>Upper Demerara-Berbice</td>\n",
       "      <td>Guyana</td>\n",
       "      <td>City formed by combining the towns of Christia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>1970</td>\n",
       "      <td>Cancún</td>\n",
       "      <td>Quintana Roo</td>\n",
       "      <td>Mexico</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1989</td>\n",
       "      <td>Palmas</td>\n",
       "      <td>Tocantins</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Was founded 1 year after the creation of the S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year                    City State, province, dept., etc.   Country  \\\n",
       "0    4000 BC  Puerto Hormiga Culture                    Cartagena  Colombia   \n",
       "1    3710 BC                  Aspero                  Norte Chico      Peru   \n",
       "2    2627 BC                   Caral                  Norte Chico      Peru   \n",
       "3     700 BC                   Ticul                      Yucatán    Mexico   \n",
       "4     500 BC                 Cholula                       Puebla    Mexico   \n",
       "..       ...                     ...                          ...       ...   \n",
       "656     1960                Brasília             Distrito Federal    Brazil   \n",
       "657     1970                Belmopan                         Cayo    Belize   \n",
       "658     1970                  Linden       Upper Demerara-Berbice    Guyana   \n",
       "659     1970                  Cancún                 Quintana Roo    Mexico   \n",
       "660     1989                  Palmas                    Tocantins    Brazil   \n",
       "\n",
       "                                                 Notes  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "..                                                 ...  \n",
       "656           Created in 1960 as the national capital.  \n",
       "657                                                     \n",
       "658  City formed by combining the towns of Christia...  \n",
       "659                                                     \n",
       "660  Was founded 1 year after the creation of the S...  \n",
       "\n",
       "[661 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>655 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year\n",
       "0     200\n",
       "1     524\n",
       "2     500\n",
       "3     600\n",
       "4    1000\n",
       "..    ...\n",
       "650  1960\n",
       "651  1970\n",
       "652  1970\n",
       "653  1970\n",
       "654  1989\n",
       "\n",
       "[655 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = table[~table[\"Year\"].str.contains('BC')][[\"Year\"]]\n",
    "table.reset_index(drop=True, inplace=True)\n",
    "table\n",
    "#table = table.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,row in table.iterrows():\n",
    "    row = row.to_frame().transpose()\n",
    "    row.reset_index(drop=True,inplace=True)\n",
    "    inp = tokenizer(table=row,\n",
    "          queries=item.utterance,\n",
    "          truncation=True,\n",
    "          padding=\"max_length\",\n",
    "          return_tensors=\"pt\"\n",
    "        )\n",
    "    out = model(**inp)\n",
    "    if torch.max(inp['token_type_ids'])>100:\n",
    "        print(torch.max(inp['token_type_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tokenizer(table=table,\n",
    "          queries=item.utterance,\n",
    "          truncation=True,\n",
    "          padding=\"max_length\",\n",
    "          return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831\n"
     ]
    }
   ],
   "source": [
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "        168, 169])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(inp['token_type_ids'][:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp['token_type_ids'][:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22751/3223343822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, table_mask, labels, aggregation_labels, float_answer, numeric_values, numeric_values_scale, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         outputs = self.tapas(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model(**inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "tensor(29408)\n",
      "tensor(0)\n",
      "attention_mask\n",
      "tensor(1)\n",
      "tensor(0)\n",
      "token_type_ids\n",
      "tensor(341)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for k,v in err.items():\n",
    "    print(k)\n",
    "    print(torch.max(v))\n",
    "    print(torch.min(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3784/524743119.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, table_mask, labels, aggregation_labels, float_answer, numeric_values, numeric_values_scale, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         outputs = self.tapas(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model(**err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m(1852)\u001b[0;36membedding\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1850 \u001b[0;31m        \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1851 \u001b[0;31m        \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1852 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1853 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1854 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m(124)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    122 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 124 \u001b[0;31m        return F.embedding(\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    126 \u001b[0;31m            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(327)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    325 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    326 \u001b[0;31m            \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 327 \u001b[0;31m            \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    328 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    329 \u001b[0;31m        \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(906)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    904 \u001b[0;31m        \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    905 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 906 \u001b[0;31m        embedding_output = self.embeddings(\n",
      "\u001b[0m\u001b[0;32m    907 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    908 \u001b[0;31m        )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(1147)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1145 \u001b[0;31m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1146 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1147 \u001b[0;31m        outputs = self.tapas(\n",
      "\u001b[0m\u001b[0;32m   1148 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1149 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m   1142 \u001b[0m            \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1143 \u001b[0m            \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mlogits_aggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1144 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m   1145 \u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1146 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1147 \u001b[0;31m        outputs = self.tapas(\n",
      "\u001b[0m\u001b[1;32m   1148 \u001b[0m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1149 \u001b[0m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1150 \u001b[0m            \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1151 \u001b[0m            \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1152 \u001b[0m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(906)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    904 \u001b[0;31m        \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    905 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 906 \u001b[0;31m        embedding_output = self.embeddings(\n",
      "\u001b[0m\u001b[0;32m    907 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    908 \u001b[0;31m        )\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/transformers/models/tapas/modeling_tapas.py\u001b[0m(327)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    325 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_token_type_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    326 \u001b[0;31m            \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"token_type_embeddings_{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 327 \u001b[0;31m            \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    328 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    329 \u001b[0;31m        \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  getattr(self,token_type_embeddings_4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'token_type_embeddings_4' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  getattr(self,'token_type_embeddings_4')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(256, 1024)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.token_type_embeddings_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(256, 1024)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(token_type_id[:,:,i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: unexpected EOF while parsing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(token_type_id[:,:,i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'token_type_id' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(token_type_ids[:,:,i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(341)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  token_type_ids[:,:,i].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.token_type_embeddings_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(2, 1024)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.token_type_embeddings_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(256, 1024)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.token_type_embeddings_4(token_type_ids[:,:,i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** IndexError: index out of range in self\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(self.token_type_embeddings_4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TypeError: max(): argument 'input' (position 1) must be Tensor, not Embedding\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  torch.max(self.token_type_embeddings_4.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1059, grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tp/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m(124)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    122 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    123 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 124 \u001b[0;31m        return F.embedding(\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    126 \u001b[0;31m            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0, 341,   0,   0,   0,   0,\n",
      "           0, 340, 340,   0,   0,   0,   0,   0, 339, 339,   0,   0,   0,   0,\n",
      "           6,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   2,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   4,   4,\n",
      "           0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0,   0,\n",
      "           5,   0,   0,   0,   0,   0,   7,   0,   0,   0,   7,   0,   0,   0,\n",
      "           0,   8,   8,   0,   0,   0,   0,   0,   9,   0,   0,   0,   0,   0,\n",
      "           9,   0,   0,   0,   0,   0,   0,  10,   0,   0,   0,   0,   0,  11,\n",
      "          11,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12,  12,   0,   0,\n",
      "           0,   0,   0,  13,  13,   0,   0,   0,   0,   0,   0,   0,   0,  14,\n",
      "          14,   0,   0,   0,  15,  15,   0,   0,   0,  16,  16,   0,   0,   0,\n",
      "           0,   0,   0,  17,  17,   0,   0,   0,  18,  18,   0,   0,   0,   0,\n",
      "           0,  18,  18,   0,   0,   0,  19,  19,   0,   0,   0,   0,  20,  20,\n",
      "           0,   0,   0,   0,   0,  21,  21,   0,   0,   0,   0,   0,   0,  21,\n",
      "          21,   0,   0,   0,   0,   0,   0,  22,  22,   0,   0,   0,   0,   0,\n",
      "          22,  22,   0,   0,   0,   0,   0,  23,  23,   0,   0,   0,   0,   0,\n",
      "           0,  24,  24,   0,   0,   0,  25,  25,   0,   0,   0,  26,  26,   0,\n",
      "           0,   0,   0,  26,  26,   0,   0,   0,   0,  27,  27,   0,   0,   0,\n",
      "           0,   0,  28,  28,   0,   0,   0,   0,   0,   0,  28,  28,   0,   0,\n",
      "           0,   0,  29,  29,   0,   0,   0,   0,  29,  29,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,  29,  29,   0,   0,   0,   0,   0,   0,  30,\n",
      "          30,   0,   0,   0,   0,  30,  30,   0,   0,   0,   0,   0,   0,   0,\n",
      "          30,  30,   0,   0,   0,   0,  31,  31,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,  31,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          32,  32,   0,   0,   0,   0,   0,   0,  33,  33,   0,   0,   0,   0,\n",
      "           0,   0,   0,  34,  34,   0,   0,   0,   0,   0,   0,  35,  35,   0,\n",
      "           0,   0,   0,  36,  36,   0,   0,   0,  36,  36,   0,   0,   0,   0,\n",
      "           0,  36,  36,   0,   0,   0,   0,  36,  36,   0,   0,   0,   0,   0,\n",
      "           0,   0,  37,  37,   0,   0,   0,   0,   0,   0,  37,  37,   0,   0,\n",
      "           0,   0,   0,  38,  38,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
      "          38,   0,   0,   0,   0,   0,   0,   0,  38,  38,   0,   0,   0,   0,\n",
      "          38,  38,   0,   0,   0,   0,   0,   0,  39,  39,   0,   0,   0,  39,\n",
      "          39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,  39,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,  39,  39,   0,   0,   0,   0,   0,\n",
      "          39,  39,   0,   0,   0,   0,   0,  40,  40,   0,   0,   0,  40,  40,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_predictions_string = [id2aggregation[x] for x in predicted_aggregation_indices]\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "  if len(coordinates) == 1:\n",
    "    # only a single cell:\n",
    "    answers.append(table.iat[coordinates[0]])\n",
    "  else:\n",
    "    # multiple cells\n",
    "    cell_values = []\n",
    "    for coordinate in coordinates:\n",
    "       cell_values.append(table.iat[coordinate])\n",
    "    answers.append(\", \".join(cell_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path) as f:\n",
    "    headers = f.readline().strip('\\n').split('\\t')\n",
    "    lines = [l.strip('\\n').split('\\t') for l in f]\n",
    "data = pd.DataFrame(lines,columns=headers)\n",
    "dataset = TableDataset(data, tokenizer)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-618396cc63ee8cfa\n",
      "Reusing dataset pandas (/root/.cache/huggingface/datasets/pandas/default-618396cc63ee8cfa/0.0.0/6197c1e855b639d75a767140856841a562b7a71d129104973fe1962594877ade)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('pandas',data_files={\n",
    "    #'train':'random-split-1-train.pkl',\n",
    "    'dev':'random-split-1-dev.pkl',\n",
    "    'test':'test.pkl'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(example):\n",
    "    return _load_table(example['context'])\n",
    "def encode(example):\n",
    "    table = load_table(example)\n",
    "    question = example['utterance']\n",
    "    encoding = tokenizer(table=table,queries=question, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "    encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99107bdc1057424b829016a9473e579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds=ds.map(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(ds['test'][0]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ds:\n",
    "    for i in range(len(ds[split])):\n",
    "        inputs = encode(ds[split][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool,cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(cpu_count()//2) as p:\n",
    "    ds['test'] = p.map(encode,ds['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    ds['dev'] = p.map(encode,ds['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ds:\n",
    "    torch.save(ds[split],f'preprocessed_{split}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-618396cc63ee8cfa\n",
      "Reusing dataset pandas (/root/.cache/huggingface/datasets/pandas/default-618396cc63ee8cfa/0.0.0/6197c1e855b639d75a767140856841a562b7a71d129104973fe1962594877ade)\n"
     ]
    }
   ],
   "source": [
    "dstb = load_dataset('pandas',data_files={\n",
    "    #'train':'random-split-1-train.pkl',\n",
    "    'dev':'random-split-1-dev.pkl',\n",
    "    'test':'test.pkl'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'utterance', 'context', 'targetValue'],\n",
       "    num_rows: 4344\n",
       "})"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dstb['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_wrap(ex):\n",
    "    ex['context'] = load_table(ex)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fe0b4c696b4f9792f1fd501864b71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8c84589230402a917ce8869227524c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4344 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dstb = dstb.map(load_table_wrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_encode(ex):\n",
    "    table = load_table(example)\n",
    "    question = example['utterance']\n",
    "    encoding = tokenizer(table=table,queries=question, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
    "    encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgftapas",
   "language": "python",
   "name": "hgftapas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
