{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_predictions(path):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t', quotechar='\"',quoting=csv.QUOTE_ALL,escapechar='\\\\')\n",
    "        headers = next(reader)\n",
    "        table = pd.DataFrame(list(reader),columns=headers)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('/workspace/hsiehcc/tapas/')\n",
    "preds_dir = base_dir/'results/wtq/model'\n",
    "split='random-split-1-dev'#'test','random-split-1-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_fl(fl,prec=1,style='%'):\n",
    "    return f\"{fl:.{prec}{style}}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tf preprocessed refs: 2810\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed ref file\n",
    "ref = _load_predictions(preds_dir/'..'/f'{split}.tsv')\n",
    "ref.loc[:, 'answer_coordinates'] = ref[\"answer_coordinates\"].apply(eval)\n",
    "ref.loc[:,'answer_coordinates'] = ref[\"answer_coordinates\"].apply(lambda x:set(map(eval,x)))\n",
    "ref = ref.rename(columns={'answer_coordinates':'answer_coordinates_gold'})\n",
    "ref = ref[['id','answer_coordinates_gold']]\n",
    "print('Total tf preprocessed refs:',len(ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-1, -1)}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref['answer_coordinates_gold'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2810\n",
      "Accuracy 52.5%\n",
      "Total Error 1335 47.5%\n"
     ]
    }
   ],
   "source": [
    "# load predictions marked by official evaluator\n",
    "marks = _load_predictions(base_dir/'formatted_predictions'/f'{split}_marked.tsv')\n",
    "print('Total', len(marks))\n",
    "errlen = len(marks[marks['mark']=='false'])\n",
    "print('Accuracy',_format_fl(1-errlen/len(marks)))\n",
    "print('Total Error', errlen, _format_fl(errlen/len(marks)))\n",
    "#marks.loc[:,'answer'] = marks['answer'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors that have no output: 363 27.2% of all errors\n"
     ]
    }
   ],
   "source": [
    "# load original prediction file with prediction details\n",
    "preds = _load_predictions(preds_dir/f'{split}.tsv')\n",
    "missing = len(marks)-len(preds)\n",
    "print('Errors that have no output:', missing, _format_fl(missing/errlen),'of all errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has prediction: 2447\n"
     ]
    }
   ],
   "source": [
    "# merge the marks with the ones that are predicted\n",
    "combined = pd.merge(preds,marks,left_on='id',right_on='id',how='inner')\n",
    "combined = pd.merge(combined,ref,left_on='id',right_on='id',how='inner')\n",
    "combined = combined.sort_values(by='id',ascending=True, key=lambda y:y.map(lambda x:int(x.split('-')[1])))\n",
    "combined.loc[:, 'answers'] = combined[\"answers\"].apply(eval)\n",
    "combined.loc[:, 'answer_coordinates'] = combined[\"answer_coordinates\"].apply(eval)\n",
    "combined.loc[:,'answer_coordinates'] = combined[\"answer_coordinates\"].apply(lambda x:set(map(eval,x)))\n",
    "print('Has prediction:', len(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1), (2, 1), (3, 1), (6, 1), (8, 1)}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['answer_coordinates'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors that have final output: 972 , 72.8% of all errors\n"
     ]
    }
   ],
   "source": [
    "# Analyze Error Subset with predictions\n",
    "combined = combined[combined['mark']=='false']\n",
    "print('Errors that have final output:', len(combined), f', {_format_fl(len(combined)/errlen)} of all errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors wo ans coordinate predictions: 21 1.6%\n",
      "Total Coordinate Errors 972 72.8%\n",
      "Errors w coor pred but wrong 951 71.2%\n"
     ]
    }
   ],
   "source": [
    "# Coordinate Prediction Errors\n",
    "# Didn't produce answer coordinates\n",
    "empt_coor = len(combined[combined['answers'].map(len)==0][\"answers\"])\n",
    "nonempt = combined[combined['answers'].map(len)!=0]\n",
    "assert len(nonempt)+empt_coor == len(combined)\n",
    "assert empt_coor==len(combined[combined['answer_coordinates'].map(len)==0][\"answer_coordinates\"])\n",
    "print('Errors wo ans coordinate predictions:',empt_coor,_format_fl(empt_coor/errlen))\n",
    "noempt_coor_err= len(nonempt[nonempt['answer_coordinates']!= nonempt['answer_coordinates_gold']])\n",
    "all_coor_err=len(combined[combined['answer_coordinates']!= combined['answer_coordinates_gold']])\n",
    "print('Total Coordinate Errors', all_coor_err,_format_fl(all_coor_err/errlen))\n",
    "print('Errors w coor pred but wrong', noempt_coor_err,_format_fl(noempt_coor_err/errlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04119850187265917"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55/errlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Aggregation Errors 495\n",
      "Aggregation Errors among the ans w coor predictions 487 36.5%\n"
     ]
    }
   ],
   "source": [
    "# Aggregation Errors\n",
    "print('Total Aggregation Errors', len(combined[combined['pred_aggr']!= combined['gold_aggr']]))\n",
    "wrong_op = len(nonempt[nonempt['pred_aggr']!= nonempt['gold_aggr']])\n",
    "print('Aggregation Errors among the ans w coor predictions', wrong_op,_format_fl(wrong_op/errlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(7, 1), (8, 1), (9, 1), (10, 1), (11, 1)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['answer_coordinates'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_coordinates_gold</th>\n",
       "      <th>answers</th>\n",
       "      <th>gold_aggr</th>\n",
       "      <th>mark</th>\n",
       "      <th>position</th>\n",
       "      <th>pred_aggr</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'confey']</td>\n",
       "      <td>{(5, 0)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 0, 'row_index': 5, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nt-2-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'14749.0']</td>\n",
       "      <td>{(0, 2)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 2, 'row_index': 0, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nt-3-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'kert toobal']</td>\n",
       "      <td>{(1, 1)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 1, 'row_index': 1, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nt-9-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'iran']</td>\n",
       "      <td>{(7, 1)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 1, 'row_index': 7, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nt-24-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'1.0']</td>\n",
       "      <td>{(9, 3)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 3, 'row_index': 9, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>nt-40-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'12.0']</td>\n",
       "      <td>{(0, 1), (13, 1), (6, 1), (3, 1), (17, 1), (2,...</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 1, 'row_index': 0, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>nt-14076-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'w 39-12']</td>\n",
       "      <td>{(1, 6)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 6, 'row_index': 1, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nt-14082-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0</td>\n",
       "      <td>[u\"b'in music\"]</td>\n",
       "      <td>{(8, 5)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 5, 'row_index': 8, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nt-14097-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'4.0']</td>\n",
       "      <td>{(0, 1), (11, 1), (4, 1), (1, 1)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 1, 'row_index': 0, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>nt-14107-0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0</td>\n",
       "      <td>[u'alex tagliani']</td>\n",
       "      <td>{(4, 2)}</td>\n",
       "      <td>{(-1, -1)}</td>\n",
       "      <td>[{'column_index': 2, 'row_index': 4, 'begin_to...</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nt-14144-0_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     annotator              answer  \\\n",
       "940          0         [u'confey']   \n",
       "1101         0        [u'14749.0']   \n",
       "2257         0    [u'kert toobal']   \n",
       "998          0           [u'iran']   \n",
       "1290         0            [u'1.0']   \n",
       "...        ...                 ...   \n",
       "791          0           [u'12.0']   \n",
       "792          0        [u'w 39-12']   \n",
       "795          0     [u\"b'in music\"]   \n",
       "796          0            [u'4.0']   \n",
       "800          0  [u'alex tagliani']   \n",
       "\n",
       "                                     answer_coordinates  \\\n",
       "940                                            {(5, 0)}   \n",
       "1101                                           {(0, 2)}   \n",
       "2257                                           {(1, 1)}   \n",
       "998                                            {(7, 1)}   \n",
       "1290                                           {(9, 3)}   \n",
       "...                                                 ...   \n",
       "791   {(0, 1), (13, 1), (6, 1), (3, 1), (17, 1), (2,...   \n",
       "792                                            {(1, 6)}   \n",
       "795                                            {(8, 5)}   \n",
       "796                   {(0, 1), (11, 1), (4, 1), (1, 1)}   \n",
       "800                                            {(4, 2)}   \n",
       "\n",
       "     answer_coordinates_gold  \\\n",
       "940               {(-1, -1)}   \n",
       "1101              {(-1, -1)}   \n",
       "2257              {(-1, -1)}   \n",
       "998               {(-1, -1)}   \n",
       "1290              {(-1, -1)}   \n",
       "...                      ...   \n",
       "791               {(-1, -1)}   \n",
       "792               {(-1, -1)}   \n",
       "795               {(-1, -1)}   \n",
       "796               {(-1, -1)}   \n",
       "800               {(-1, -1)}   \n",
       "\n",
       "                                                answers gold_aggr   mark  \\\n",
       "940   [{'column_index': 0, 'row_index': 5, 'begin_to...         0  false   \n",
       "1101  [{'column_index': 2, 'row_index': 0, 'begin_to...         0  false   \n",
       "2257  [{'column_index': 1, 'row_index': 1, 'begin_to...         0  false   \n",
       "998   [{'column_index': 1, 'row_index': 7, 'begin_to...         0  false   \n",
       "1290  [{'column_index': 3, 'row_index': 9, 'begin_to...         0  false   \n",
       "...                                                 ...       ...    ...   \n",
       "791   [{'column_index': 1, 'row_index': 0, 'begin_to...         0  false   \n",
       "792   [{'column_index': 6, 'row_index': 1, 'begin_to...         0  false   \n",
       "795   [{'column_index': 5, 'row_index': 8, 'begin_to...         0  false   \n",
       "796   [{'column_index': 1, 'row_index': 0, 'begin_to...         0  false   \n",
       "800   [{'column_index': 2, 'row_index': 4, 'begin_to...         0  false   \n",
       "\n",
       "     position pred_aggr   question_id  \n",
       "940         0         0      nt-2-0_0  \n",
       "1101        0         1      nt-3-0_0  \n",
       "2257        0         0      nt-9-0_0  \n",
       "998         0         0     nt-24-0_0  \n",
       "1290        0         3     nt-40-0_0  \n",
       "...       ...       ...           ...  \n",
       "791         0         3  nt-14076-0_0  \n",
       "792         0         1  nt-14082-0_0  \n",
       "795         0         0  nt-14097-0_0  \n",
       "796         0         3  nt-14107-0_0  \n",
       "800         0         0  nt-14144-0_0  \n",
       "\n",
       "[972 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = combined.columns.difference(['id'])\n",
    "combined[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = combined.set_index('id')[['pred_aggr','answer_coordinates','answer','mark']].to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Preprocessed TF Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "raw_ds = tf.data.TFRecordDataset('results/wtq/tf_examples/random-split-1-dev.tfrecord', compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Dump interactions to json for flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.protos import interaction_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_df(dic):\n",
    "    columns = [f\"{v}-{k}\" for d in dic['columns'] for k,v in d.items()]\n",
    "    rows = [{columns[i]: ' '.join(list(d.values())) for i, d in enumerate(row['cells'])} for row in dic['rows']]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view interaction protobuf\n",
    "dics = {}\n",
    "split = 'random-split-1-dev'\n",
    "for value in tf.data.TFRecordDataset(f'results/wtq/interactions/{split}.tfrecord'):\n",
    "    interaction = interaction_pb2.Interaction()\n",
    "    interaction.ParseFromString(value.numpy())\n",
    "    d = MessageToDict(interaction)\n",
    "    d['table_id'] = d['table']['tableId']\n",
    "    d['table'] = _to_df(d['table']).to_dict()\n",
    "    dics[d['id'].rsplit('-',1)[0]] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['columns', 'rows', 'tableId'])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['table'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'results/wtq/for_flask/{split}.json','w') as f:\n",
    "    json.dump(dics,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810\n"
     ]
    }
   ],
   "source": [
    "print(len(dics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome-text</th>\n",
       "      <th>Year-text</th>\n",
       "      <th>Championship-text</th>\n",
       "      <th>Surface-text</th>\n",
       "      <th>Opponent-text</th>\n",
       "      <th>Score-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(runner-up)</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>(canada)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(guillermo canas)</td>\n",
       "      <td>(4-6, 5-7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(winner)</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>(montreal)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(david nalbandian)</td>\n",
       "      <td>(6-1, 6-3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(winner)</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>(cincinnati)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(mardy fish)</td>\n",
       "      <td>(4-6, 7-6(7-3), 7-6(7-4))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(winner)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>(miami)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(guillermo coria)</td>\n",
       "      <td>(6-7(2-7), 6-3, 6-1, ret)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(runner-up)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>(toronto)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(roger federer)</td>\n",
       "      <td>(5-7, 3-6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(runner-up)</td>\n",
       "      <td>(2005)</td>\n",
       "      <td>(cincinnati)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(roger federer)</td>\n",
       "      <td>(3-6, 5-7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(winner)</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>(cincinnati)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(juan carlos ferrero)</td>\n",
       "      <td>(6-3, 6-4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(runner-up)</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>(indian wells)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(ivan ljubicic)</td>\n",
       "      <td>(6-7(3-7), 6-7(5-7))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(winner)</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>(miami)</td>\n",
       "      <td>(hard)</td>\n",
       "      <td>(tomas berdych)</td>\n",
       "      <td>(7-5, 6-4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Outcome-text Year-text Championship-text Surface-text  \\\n",
       "0  (runner-up)    (2002)          (canada)       (hard)   \n",
       "1     (winner)    (2003)        (montreal)       (hard)   \n",
       "2     (winner)    (2003)      (cincinnati)       (hard)   \n",
       "3     (winner)    (2004)           (miami)       (hard)   \n",
       "4  (runner-up)    (2004)         (toronto)       (hard)   \n",
       "5  (runner-up)    (2005)      (cincinnati)       (hard)   \n",
       "6     (winner)    (2006)      (cincinnati)       (hard)   \n",
       "7  (runner-up)    (2010)    (indian wells)       (hard)   \n",
       "8     (winner)    (2010)           (miami)       (hard)   \n",
       "\n",
       "           Opponent-text                 Score-text  \n",
       "0      (guillermo canas)                 (4-6, 5-7)  \n",
       "1     (david nalbandian)                 (6-1, 6-3)  \n",
       "2           (mardy fish)  (4-6, 7-6(7-3), 7-6(7-4))  \n",
       "3      (guillermo coria)  (6-7(2-7), 6-3, 6-1, ret)  \n",
       "4        (roger federer)                 (5-7, 3-6)  \n",
       "5        (roger federer)                 (3-6, 5-7)  \n",
       "6  (juan carlos ferrero)                 (6-3, 6-4)  \n",
       "7        (ivan ljubicic)       (6-7(3-7), 6-7(5-7))  \n",
       "8        (tomas berdych)                 (7-5, 6-4)  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_to_df(dics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Preprocessing Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('results/wtq/tf_examples/random-split-1-dev_errors.json') as f:\n",
    "    errors = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find all answers 98\n",
      "Invalid answer 250\n",
      "Too many rows 15\n",
      "total 363\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "s=set()\n",
    "t = 0\n",
    "for k,v in errors.items():\n",
    "    if k=='Invalid answer':\n",
    "        s|=set(v) \n",
    "    print(k,len(v))\n",
    "    t+=len(v)\n",
    "print('total',t)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid Answers Breakdown\n",
    "with open('results/wtq/interactions/err_ids.json') as f:\n",
    "    bkdns = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot parse answer: [float_value: Contains digits, but Unable to convert value to float]\n",
      "75\n",
      "Cannot parse answer: [float_value: Cannot convert to multiple answers to single float]\n",
      "7\n",
      "Cannot parse answer: [float_value: Unable to convert value to float]\n",
      "169\n",
      "Cannot parse answer: [answer_coordinates: Assignment is ambiguous][float_value: Cannot convert to multiple answers to single float]\n",
      "1\n",
      "random-split-1-dev.tsv total 252\n"
     ]
    }
   ],
   "source": [
    "se= set()\n",
    "split = 'random-split-1-dev.tsv'\n",
    "for k,v in bkdns[split].items():\n",
    "    v = list(map(lambda x:x.split('_')[0],v))\n",
    "    bkdns[split][k] = v\n",
    "    print(k)\n",
    "    print(len(v))\n",
    "    se|=set(v)\n",
    "print(f'{split} total',len(se))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nt-3899-0', 'nt-11953-0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(se.difference(s))\n",
    "'nt-11953-0' in errors[\"Too many rows\"] and 'nt-3899-0' in errors[\"Too many rows\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate the float value conversion errors\n",
    "See if we can still convert them to tf examples without float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_key = \"Cannot parse answer: [float_value: Unable to convert value to float]\"\n",
    "maj_err = set(bkdns['random-split-1-dev.tsv'][err_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.protos import interaction_pb2\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view interaction protobuf\n",
    "todo = []\n",
    "split = 'random-split-1-dev'\n",
    "corr = []\n",
    "\n",
    "for value in tf.python_io.tf_record_iterator(f'results/wtq/interactions/{split}.tfrecord'):\n",
    "    interaction = interaction_pb2.Interaction()\n",
    "    interaction.ParseFromString(value)\n",
    "    if interaction.id in maj_err:\n",
    "        todo.append(interaction)\n",
    "    elif len(corr)<3:\n",
    "        corr.append(interaction)\n",
    "# eager execution\n",
    "# for value in tf.data.TFRecordDataset([f'results/wtq/interactions/{split}.tfrecord']):\n",
    "#     interaction = interaction_pb2.Interaction()\n",
    "#     interaction.ParseFromString(value.numpy())\n",
    "#     if interaction.id in maj_err:\n",
    "#         todo.append(interaction)\n",
    "#     elif len(corr)<3:\n",
    "#         corr.append(interaction)\n",
    "        \n",
    "#     d = MessageToDict(interaction)\n",
    "#     d['table_id'] = d['table']['tableId']\n",
    "#     d['table'] = _to_df(d['table']).to_dict()\n",
    "#     dics[d['id'].rsplit('-',1)[0]] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.utils import tf_example_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.utils import pruning_utils\n",
    "token_selector = pruning_utils.HeuristicExactMatchTokenSelector(\n",
    "    'tapas_wtq_wikisql_sqa_inter_masklm_large_reset/vocab.txt', \n",
    "    512, \n",
    "    pruning_utils.SelectionType.COLUMN,\n",
    "    # Only relevant for SQA where questions come in sequence\n",
    "    use_previous_answer=True,\n",
    "    use_previous_questions=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf_example_utils.ClassifierConversionConfig(\n",
    "    vocab_file='tapas_wtq_wikisql_sqa_inter_masklm_large_reset/vocab.txt', \n",
    "    max_seq_length=512, \n",
    "    max_column_id=512, \n",
    "    max_row_id=512, \n",
    "    strip_column_names=False, \n",
    "    cell_trim_length=-1, \n",
    "    add_aggregation_candidates=False, \n",
    "    expand_entity_descriptions=False, \n",
    "    use_entity_title=False, \n",
    "    entity_descriptions_sentence_limit=5, \n",
    "    use_document_title=False, \n",
    "    update_answer_coordinates=False, \n",
    "    drop_rows_to_fit=False, \n",
    "    use_context_title=False, \n",
    "    trim_question_ids=False, \n",
    "    label_sampling_rate={}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf_example_utils.ToClassifierTensorflowExample(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for ex in todo:\n",
    "    ex = token_selector.annotated_interaction(ex)\n",
    "    if len(ex.questions[0].text)>0:\n",
    "        print(ex.questions[0].text)\n",
    "    examples.append(converter.convert(ex,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = MessageToDict(examples[0].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'column_ids', 'input_mask', 'aggregation_function_id', 'segment_ids', 'table_id', 'numeric_relations', 'numeric_values_scale', 'numeric_values', 'row_ids', 'prev_label_ids', 'question_id_ints', 'question_id', 'answer', 'column_ranks', 'label_ids', 'classification_class_index', 'table_id_hash', 'inv_column_ranks'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['feature'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.example.feature_pb2.Feature"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(examples[0].features.feature['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapas.models import tapas_classifier_model\n",
    "from tapas.models.bert import modeling\n",
    "from tapas.utils import tasks, hparam_utils\n",
    "from tapas.utils import text_utils\n",
    "\n",
    "\n",
    "task = tasks.Task.WTQ\n",
    "hparams = hparam_utils.get_hparams(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/wtq/model/model.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = 'results/wtq/model'\n",
    "print(tf.train.latest_checkpoint(\n",
    "    checkpoint_dir\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = 'tapas_wtq_wikisql_sqa_inter_masklm_large_reset/bert_config.json'\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tapas_config = tapas_classifier_model.TapasClassifierConfig(\n",
    "    bert_config= bert_config, \n",
    "    init_checkpoint='tapas_wtq_wikisql_sqa_inter_masklm_large_reset/model.ckpt', \n",
    "    learning_rate=1.93581e-05, \n",
    "    num_train_steps=50000, \n",
    "    num_warmup_steps=6448, \n",
    "    use_tpu=False, \n",
    "    positive_weight=10.0, \n",
    "    num_aggregation_labels=4, \n",
    "    num_classification_labels=0, \n",
    "    aggregation_loss_importance=1.0, \n",
    "    use_answer_as_supervision=True, \n",
    "    answer_loss_importance=1.0, \n",
    "    use_normalized_answer_loss=False, \n",
    "    huber_loss_delta=0.121194, \n",
    "    temperature=0.0352513, \n",
    "    agg_temperature=1.0, \n",
    "    use_gumbel_for_cells=False, \n",
    "    use_gumbel_for_agg=False, \n",
    "    average_approximation_function=tapas_classifier_model.AverageApproximationFunction.RATIO, \n",
    "    cell_select_pref=0.207951, \n",
    "    answer_loss_cutoff=0.664694, \n",
    "    grad_clipping=10.0, \n",
    "    max_num_rows=64, \n",
    "    max_num_columns=32, \n",
    "    average_logits_per_cell=False, \n",
    "    select_one_column=True, \n",
    "    allow_empty_column_selection=False, \n",
    "    disabled_features=[], \n",
    "    init_cell_selection_weights_to_zero=True, \n",
    "    disable_position_embeddings=False, \n",
    "    reset_position_index_per_cell=False, \n",
    "    disable_per_token_loss=False, \n",
    "    span_prediction=tapas_classifier_model.SpanPredictionMode(\n",
    "          hparams.get('span_prediction',\n",
    "                      tapas_classifier_model.SpanPredictionMode.NONE)),\n",
    "    proj_value_length=None,\n",
    "    reset_output_cls=False,\n",
    "    classification_label_weight=None,\n",
    "    mask_examples_without_labels=False,\n",
    "    table_pruning_config_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = tapas_classifier_model.model_fn_builder(tapas_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from tapas.run_task_main import _predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_patterns='results/wtq/tf_examples/random-split-1-dev.tfrecord'\n",
    "data_format='tfrecord'\n",
    "compression_type='GZIP'\n",
    "is_training=False\n",
    "max_seq_length=512\n",
    "max_predictions_per_seq=20\n",
    "add_aggregation_function_id=True\n",
    "add_classification_labels=False\n",
    "add_answer=True\n",
    "include_id=False\n",
    "add_candidate_answers=False,\n",
    "max_num_candidates=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = {\n",
    "      \"input_ids\":\n",
    "          tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"input_mask\":\n",
    "          tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"segment_ids\":\n",
    "          tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"column_ids\":\n",
    "          tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"row_ids\":\n",
    "          tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"prev_label_ids\":\n",
    "          tf.io.FixedLenFeature([max_seq_length],\n",
    "                             tf.int64,\n",
    "                             default_value=[0] * max_seq_length),\n",
    "      \"column_ranks\":\n",
    "          tf.io.FixedLenFeature(\n",
    "              [max_seq_length],\n",
    "              tf.int64,\n",
    "              default_value=[0] * max_seq_length,\n",
    "          ),\n",
    "      \"inv_column_ranks\":\n",
    "          tf.io.FixedLenFeature(\n",
    "              [max_seq_length],\n",
    "              tf.int64,\n",
    "              default_value=[0] * max_seq_length,\n",
    "          ),\n",
    "      \"numeric_relations\":\n",
    "          tf.io.FixedLenFeature([max_seq_length],\n",
    "                             tf.int64,\n",
    "                             default_value=[0] * max_seq_length),\n",
    "  }\n",
    "feature_types.update({\n",
    "        \"label_ids\":\n",
    "            tf.io.FixedLenFeature(\n",
    "                [max_seq_length],\n",
    "                tf.int64,\n",
    "                default_value=[0] * max_seq_length,\n",
    "            ),\n",
    "    })\n",
    "feature_types.update({\n",
    "        \"question_id_ints\":\n",
    "            tf.io.FixedLenFeature([text_utils.DEFAULT_INTS_LENGTH],\n",
    "                               tf.int64,\n",
    "                               default_value=[0] *\n",
    "                               text_utils.DEFAULT_INTS_LENGTH),\n",
    "    })\n",
    "\n",
    "if add_aggregation_function_id:\n",
    "      feature_types.update({\n",
    "          \"aggregation_function_id\": tf.io.FixedLenFeature([1], tf.int64),\n",
    "      })\n",
    "if add_classification_labels:\n",
    "      feature_types.update({\n",
    "          \"classification_class_index\": tf.io.FixedLenFeature([1], tf.int64),\n",
    "      })\n",
    "    # Features for the weakly supervised setting.\n",
    "if add_answer:\n",
    "      feature_types.update({\n",
    "          \"numeric_values\":\n",
    "              tf.io.FixedLenFeature(\n",
    "                  [max_seq_length],\n",
    "                  tf.float32,\n",
    "                  default_value=[0] * max_seq_length,\n",
    "              ),\n",
    "          \"numeric_values_scale\":\n",
    "              tf.io.FixedLenFeature(\n",
    "                  [max_seq_length],\n",
    "                  tf.float32,\n",
    "                  default_value=[0] * max_seq_length,\n",
    "              ),\n",
    "          \"answer\":\n",
    "              tf.io.FixedLenFeature(\n",
    "                  [1],\n",
    "                  tf.float32,\n",
    "                  default_value=[0],\n",
    "              ),\n",
    "      })\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parser_function(feature_types,\n",
    "                          params):\n",
    "  \"\"\"Returns a parse function that can be used by read_dataset.\"\"\"\n",
    "  del params\n",
    "\n",
    "  def parse_examples(serialized_examples):\n",
    "    features = tf.io.parse_single_example(serialized_examples, feature_types)\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(features.keys()):\n",
    "      t = features[name]\n",
    "      if t.dtype == tf.int64:\n",
    "        t = tf.cast(t, tf.int32)\n",
    "        features[name] = t\n",
    "    return features\n",
    "\n",
    "  return parse_examples\n",
    "\n",
    "def _parse_fn(serialized_example):\n",
    "    features = dict(\n",
    "        build_parser_function(feature_types,\n",
    "                                      params)(serialized_example))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = examples[0]\n",
    "ex_str = example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_int(fts):\n",
    "    for name in list(fts.keys()):\n",
    "        t = fts[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t, tf.int32)\n",
    "            fts[name] = t\n",
    "    return fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized = []\n",
    "for example in examples:\n",
    "    serialized.append(example.SerializeToString())\n",
    "#fts = tf.io.parse_single_example(ex_str, feature_types)\n",
    "fts = cast_int(tf.io.parse_example(serialized, feature_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = _parse_fn(ex_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, params):\n",
    "    parse_fn = _parse_fn\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = functools.partial(input_fn,features=fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a single element from tapas's V1 dataset\n",
    "#('tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter')\n",
    "# tf.data.experimental.get_single_element(\n",
    "#     dataset\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_input_fn = some sort of input fn that iterates through the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "taken from \n",
    "Traceback:\n",
    "```\n",
    "    tapas/models/tapas_classifier_model.py:1170\n",
    "        tapas/datasets/table_dataset.py:190\n",
    "            tapas/datasets/dataset.py:78\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.compat.v1.estimator.tpu.RunConfig(\n",
    "      cluster=None,\n",
    "      master=None,\n",
    "      model_dir='results/wtq/model',\n",
    "      tf_random_seed=None,\n",
    "      save_checkpoints_steps=1000,\n",
    "      keep_checkpoint_max=5,\n",
    "      keep_checkpoint_every_n_hours=4.0,\n",
    "      tpu_config=tf.compat.v1.estimator.tpu.TPUConfig(\n",
    "          iterations_per_loop=1000,\n",
    "          num_shards=8,\n",
    "          per_host_input_for_training=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'results/wtq/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 4.0, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.compat.v1.estimator.tpu.TPUEstimator(\n",
    "      params={'gradient_accumulation_steps': 1},\n",
    "      use_tpu=False,\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      train_batch_size=512 // 1,\n",
    "      eval_batch_size=None,\n",
    "      predict_batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = estimator.latest_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_fn(params):\n",
    "    return tf.data.Dataset.from_tensor_slices(fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:prediction_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"optimizations:0\", shape=(3,), dtype=string) must be from the same graph as Tensor(\"TensorSliceDataset_1:0\", shape=(), dtype=variant).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_initializable_iterator\u001b[0;34m(dataset, shared_name)\u001b[0m\n\u001b[1;32m   2576\u001b[0m     \u001b[0;31m# some datasets (e.g. for prefetching) override its behavior.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2577\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2578\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorSliceDataset' object has no attribute '_make_initializable_iterator'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-472e17776a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3125\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3126\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3128\u001b[0m     \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    148\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   3118\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3119\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m           yield_single_examples=yield_single_examples):\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         features, input_hooks = self._get_features_from_input_fn(\n\u001b[0;32m--> 611\u001b[0;31m             input_fn, ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    612\u001b[0m         estimator_spec = self._call_model_fn(features, None, ModeKeys.PREDICT,\n\u001b[1;32m    613\u001b[0m                                              self.config)\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_input_fn_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features_in_predict_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/util.py\u001b[0m in \u001b[0;36mparse_input_fn_result\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0minput_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0minput_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DatasetInitializerHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_initializable_iterator\u001b[0;34m(dataset, shared_name)\u001b[0m\n\u001b[1;32m   2577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2579\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_make_initializable_iterator\u001b[0;34m(self, shared_name)\u001b[0m\n\u001b[1;32m   2192\u001b[0m           \"execution is enabled. Use `for element in dataset` instead.\")\n\u001b[1;32m   2193\u001b[0m     \u001b[0m_ensure_same_dataset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshared_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m       \u001b[0mshared_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0;32m--> 375\u001b[0;31m                                    graph_rewrite_configs)\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;31m# (3) Apply autotune options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[1;32m   4363\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4364\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4365\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4366\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[0;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   3713\u001b[0m                            \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m                            \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3715\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   3716\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   5919\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5920\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5921\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5922\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5923\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   5854\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5855\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[0;32m-> 5856\u001b[0;31m                      (item, original_item))\n\u001b[0m\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"optimizations:0\", shape=(3,), dtype=string) must be from the same graph as Tensor(\"TensorSliceDataset_1:0\", shape=(), dtype=variant)."
     ]
    }
   ],
   "source": [
    "next(estimator.predict(input_fn=test_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/inspect.py\u001b[0m(1132)\u001b[0;36mgetfullargspec\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1130 \u001b[0;31m        \u001b[0;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1131 \u001b[0;31m        \u001b[0;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1132 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unsupported callable'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1133 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1134 \u001b[0;31m    \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  U\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'U' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m(257)\u001b[0;36mgetfullargspec\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    255 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_maybe_argspec_to_fullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator_argspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 257 \u001b[0;31m  \u001b[0;32mreturn\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    258 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow/python/util/function_utils.py\u001b[0m(57)\u001b[0;36mfn_args\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     55 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0m_is_callable_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m      \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 57 \u001b[0;31m    \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0m_is_bound_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m      \u001b[0;31m# If it's a bound method, it may or may not have a self/cls first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/envs/tapas/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m(2998)\u001b[0;36m_call_input_fn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2996 \u001b[0;31m      \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_fn\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2997 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m-> 2998 \u001b[0;31m    \u001b[0minput_fn_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2999 \u001b[0;31m    \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m  \u001b[0;31m# a deep copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3000 \u001b[0;31m    \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  type(input_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  Q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'Q' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregation_function_id (1,)\n",
      "answer (1,)\n",
      "column_ids (512,)\n",
      "column_ranks (512,)\n",
      "input_ids (512,)\n",
      "input_mask (512,)\n",
      "inv_column_ranks (512,)\n",
      "label_ids (512,)\n",
      "numeric_relations (512,)\n",
      "numeric_values (512,)\n",
      "numeric_values_scale (512,)\n",
      "prev_label_ids (512,)\n",
      "question_id_ints (64,)\n",
      "row_ids (512,)\n",
      "segment_ids (512,)\n"
     ]
    }
   ],
   "source": [
    "for k,v in ds[0].items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "expd = {k: v[None,:] for k,v in ds[0].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Debug Breakpoints\n",
    "\n",
    "    run_task_main.py: 482\n",
    "                    : 508\n",
    "                    : 557\n",
    "                    : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Breakpoints\n",
    "\n",
    "major preprocessing error: 244/363 are bc \"Unable to convert value to float\"\n",
    "\n",
    "```\n",
    "Num Type         Disp Enb   Where\n",
    "1   breakpoint   keep yes   at utils/interaction_utils_parser.py:254\n",
    "2   breakpoint   keep yes   at utils/interaction_utils_parser.py:249\n",
    "3   breakpoint   keep yes   at utils/interaction_utils_parser.py:243\n",
    "4   breakpoint   keep yes   at run_task_main.py:279\n",
    "        breakpoint already hit 1 time\n",
    "5   breakpoint   keep no    at utils/tf_example_utils.py:231\n",
    "        breakpoint already hit 1 time\n",
    "6   breakpoint   keep yes   at utils/tf_example_utils.py:1067\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* invalid answer -- \n",
    "    can't convert float value or no answer coordinate\n",
    "    sqa_utils:\\_parse_questions --> sets interaction.answer.is_valid=False\n",
    "    \n",
    "        |_interaction_utils_parser:parse_question\n",
    "        \n",
    "            |_ ..._parse_question :243,249,254\n",
    "            \n",
    "```\n",
    "if not question.answer.answer_coordinates and not question.answer.HasField(\n",
    "\"float_value\"):\n",
    "    raise ValueError(\"Cannot parse answer: {}\".format(error_message))\n",
    "```\n",
    "        \n",
    "* Couldn't find all answers -- \n",
    "\n",
    "    b:tf_example_utils.py:226, 231\n",
    "    \n",
    "        run_task_main:279\n",
    "    \n",
    "            tf_example_utils.ToClassifierTensorflowExample.convert\n",
    "                     :1227 -> 340 -> 242 -> 214\n",
    "                 \n",
    "* Too many rows\n",
    "  tf_example_utils......convert:\n",
    "  \n",
    "      1177/1178 -> \\_get_num_rows:1067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tapas",
   "language": "python",
   "name": "tapas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
